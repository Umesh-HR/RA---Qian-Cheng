{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Strategies:\n",
    "1. compress hsi bands to 3\n",
    "    - PCA\n",
    "2. process 3 bands a time, and merge the information in final layer for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imageio import imwrite\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read HSI Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral values at pixel (10, 10): [15360, 25696, 12608, 35728, 38368]\n"
     ]
    }
   ],
   "source": [
    "# Open the HSI TIFF file\n",
    "dataset = gdal.Open('stacked_hsi.tif', gdal.GA_ReadOnly)\n",
    "\n",
    "# Specify the pixel coordinates you are interested in (x, y)\n",
    "x, y = 10, 10  # for example\n",
    "\n",
    "# Loop through each band and read the pixel value\n",
    "pixel_spectral_values = []\n",
    "for b in range(dataset.RasterCount):\n",
    "    band = dataset.GetRasterBand(b + 1)  # Band count starts at 1\n",
    "    pixel_value = band.ReadAsArray(x, y, 1, 1)\n",
    "    pixel_spectral_values.append(pixel_value[0][0])\n",
    "\n",
    "print(f\"Spectral values at pixel ({x}, {y}):\", pixel_spectral_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_shape: (bands, rows, cols) = (5, 960, 1280)\n",
      "original value at pixel (10, 10): 15360 25696 12608 35728 38368\n"
     ]
    }
   ],
   "source": [
    "# Load the hyperspectral image\n",
    "with rasterio.open('stacked_hsi.tif') as src:\n",
    "    img = src.read()\n",
    "\n",
    "# Reshape the image for PCA; (bands, rows, cols) \n",
    "print('original_shape: (bands, rows, cols) =', img.shape)\n",
    "print('original value at pixel (10, 10):', img[0][10][10], img[1][10][10], img[2][10][10], img[3][10][10], img[4][10][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize HSI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value after standardization at pixel (10, 10): -0.9572107742415521 -0.1846613443969822 -1.1629050496800444 0.5651660433933356 0.7624890401802614\n"
     ]
    }
   ],
   "source": [
    "bands, rows, cols = img.shape\n",
    "\n",
    "# Transpose img to bring bands to the last dimension: new order (rows, columns, bands)\n",
    "img_transposed = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "# Reshape the image to have one pixel per row, and bands as columns\n",
    "pixels = img.reshape(-1, bands)\n",
    "\n",
    "# Calculate mean and standard deviation for each band\n",
    "mean = np.mean(pixels, axis=0)\n",
    "std = np.std(pixels, axis=0)\n",
    "\n",
    "# Standardize the pixels\n",
    "standardized_pixels = (pixels - mean) / std\n",
    "\n",
    "# Reshape back to original dimensions if necessary\n",
    "standardized_hsi_img = standardized_pixels.reshape(bands, rows, cols)\n",
    "\n",
    "# Now 'standardized_hsi_image' is the standardized hyperspectral image\n",
    "print('value after standardization at pixel (10, 10):', standardized_hsi_img[0][10][10], standardized_hsi_img[1][10][10], standardized_hsi_img[2][10][10], standardized_hsi_img[3][10][10], standardized_hsi_img[4][10][10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape the original HSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after reshape: (1228800, 5)\n"
     ]
    }
   ],
   "source": [
    "original_shape = img.shape\n",
    "# Reshape to (n_samples, n_features)\n",
    "hsi_reshape = img.reshape(img.shape[0], -1).T\n",
    "# 960 * 1280 = 1228800\n",
    "print('after reshape:', hsi_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA\n",
    "- Principal Component Analysis: statistical technique used for dimensionality reduction while preserving as much of the data’s variability as possible.\n",
    "\n",
    "### Normalization vs Standardization\n",
    "Outlier Sensitivity: \n",
    "Normalization can be sensitive to outliers since the minimum and maximum values are used for scaling. Standardization, on the other hand, is less sensitive to outliers because it uses the mean and standard deviation, which are less influenced by extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_reduced = pca.fit_transform(hsi_reshape)\n",
    "\n",
    "# Reshape back to (3, rows, cols)\n",
    "pca_reshaped = pca_reduced.T.reshape(3, original_shape[1], original_shape[2])\n",
    "\n",
    "# Normalize and convert data to uint8\n",
    "normalized_pca = ((pca_reshaped - pca_reshaped.min()) / (pca_reshaped.max() - pca_reshaped.min()) * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first three bands as an RGB image\n",
    "imwrite('pca_reduced.png', normalized_pca.transpose(1, 2, 0))  # Transpose to get shape (rows, cols, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Component Analysis(ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Apply ICA\n",
    "ica = FastICA(n_components=3)\n",
    "ICA_reduced = ica.fit_transform(hsi_reshape)\n",
    "\n",
    "# Reshape and process like PCA\n",
    "ICA_reshaped = ICA_reduced.T.reshape(3, original_shape[1], original_shape[2])\n",
    "\n",
    "# Normalize and convert data to uint8\n",
    "normalized_ica = ((ICA_reshaped - ICA_reshaped.min()) / (ICA_reshaped.max() - ICA_reshaped.min()) * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first three bands as an RGB image\n",
    "imwrite('ica_reduced.png', normalized_ica.transpose(1, 2, 0))  # Transpose to get shape (rows, cols, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Cosine Transform (DCT) - Fourier transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "def apply_dct(image):\n",
    "    return dct(dct(image.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def apply_idct(image):\n",
    "    return idct(idct(image.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "# Apply DCT to each band\n",
    "dct_images = np.array([apply_dct(band) for band in img])\n",
    "\n",
    "# Optionally, apply inverse DCT to see reconstruction\n",
    "reconstructed_images = np.array([apply_idct(band) for band in dct_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for compression\n",
    "threshold = np.quantile(dct_images, 0.95)\n",
    "\n",
    "# Zero out small DCT coefficients\n",
    "compressed_dct_images = np.where(np.abs(dct_images) < threshold, 0, dct_images)\n",
    "\n",
    "# Apply inverse DCT to compressed image\n",
    "compressed_images = np.array([apply_idct(band) for band in compressed_dct_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opencv/lib/python3.12/site-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: The given matrix is equal to Affine.identity or its flipped counterpart. GDAL may ignore this matrix and save no geotransform without raising an error. This behavior is somewhat driver-specific.\n",
      "  dataset = writer(\n"
     ]
    }
   ],
   "source": [
    "# Define metadata and transformation (assuming same as input)\n",
    "with rasterio.open('stacked_hsi.tif') as src:\n",
    "    meta = src.meta.copy()\n",
    "\n",
    "# Update meta to reflect any changes in dtype or number of bands\n",
    "meta.update(dtype='float32')\n",
    "\n",
    "# Save compressed image\n",
    "with rasterio.open('dct_compressed.tif', 'w', **meta) as dst:\n",
    "    dst.write(compressed_images.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Select bands at index 0, 1, 2\n",
    "rgb_image = compressed_images[[0, 2, 4], :, :]\n",
    "\n",
    "# Normalize data to 0-255\n",
    "def normalize_data(img):\n",
    "    img_min = np.min(img)\n",
    "    img_max = np.max(img)\n",
    "    return ((img - img_min) / (img_max - img_min) * 255).astype(np.uint8)\n",
    "\n",
    "# Apply normalization to each band\n",
    "rgb_normalized = np.array([normalize_data(band) for band in rgb_image])\n",
    "\n",
    "# Transpose to (height, width, channels) format required by most image libraries\n",
    "rgb_normalized = rgb_normalized.transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the RGB image as a PNG file\n",
    "imwrite('dct_compressed_024.png', rgb_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Sum of bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights - simple linear example\n",
    "num_bands = img.shape[0]\n",
    "# weights = np.linspace(1, 2, num_bands)  # Linearly increasing weights from 1 to 2\n",
    "# TODO: make them parameters - learnable. \n",
    "weights = np.array([0.5, 0.1, 0.2, 0.1, 0.1])  # Custom weights\n",
    "\n",
    "# Apply weights and sum along the band dimension\n",
    "weighted_sum = np.tensordot(weights, standardized_hsi_img, axes=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [0.5 0.1 0.2 0.1 0.1]\n",
      "weighted_sum: [[-0.6505828  -0.63230115 -0.6556062  ... -0.87544827 -0.94637951\n",
      "  -1.06246386]\n",
      " [-0.62200086 -0.65514113 -0.65273557 ... -0.98046532 -1.00845857\n",
      "  -1.09441119]\n",
      " [-0.68394832 -0.65011873 -0.6670887  ... -0.97173384 -1.04171095\n",
      "  -0.99509928]\n",
      " ...\n",
      " [-0.72783774 -0.76336198 -0.75942716 ... -0.89051906 -0.85619142\n",
      "  -0.86479726]\n",
      " [-0.69483098 -0.69567911 -0.73658176 ... -0.85021069 -0.80858551\n",
      "  -0.83943084]\n",
      " [-0.6923196  -0.71325752 -0.73765825 ... -0.84423022 -0.84590471\n",
      "  -0.79384308]]\n"
     ]
    }
   ],
   "source": [
    "print('weights:', weights)\n",
    "print('weighted_sum:', weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the weighted sum to fit into a typical image range\n",
    "weighted_sum_normalized = 255 * (weighted_sum - np.min(weighted_sum)) / (np.max(weighted_sum) - np.min(weighted_sum))\n",
    "weighted_sum_normalized = weighted_sum_normalized.astype(np.uint8)\n",
    "\n",
    "# Save resulting image\n",
    "imwrite('customized_weighted_sum.png', weighted_sum_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can process three bands at a time from a multi-band hyperspectral image (HSI) and combine the results at the final layer. This approach is a common strategy in processing hyperspectral data, especially when trying to manage the high dimensionality and correlation between spectral bands. Here’s a general outline of how you might implement this:\n",
    "1.\tBand Selection:\n",
    "\t•\tSelect subsets of bands, such as three bands at a time, that you believe contain significant information for your analysis. The selection of bands can be sequential, random, or based on some spectral characteristics like bands covering specific wavelengths of interest.\n",
    "2.\tFeature Extraction:\n",
    "\t•\tProcess each triplet of bands separately through a neural network or another machine learning model to extract features. This can involve convolutional layers if you are using deep learning, which are adept at capturing spatial and spectral features.\n",
    "3.\tCombining Features:\n",
    "\t•\tAfter processing the individual triplets, the next step is to combine the extracted features. This can be done in several ways:\n",
    "\t•\tConcatenation: The features from each triplet are concatenated into a single feature vector.\n",
    "\t•\tFeature Fusion: Use more sophisticated methods like averaging, maximum, or learned fusion methods to combine features.\n",
    "4.\tFinal Layers:\n",
    "\t•\tPass the combined features through additional layers (if needed) to make final predictions or analyses. This could be classification layers, regression layers, or other custom layers depending on your application.\n",
    "5.\tTraining and Inference:\n",
    "\t•\tDuring training, ensure that the network learns to effectively integrate the features from different band triplets. It might be beneficial to include regularization techniques to prevent overfitting given the high-dimensional nature of HSI data.\n",
    "\t•\tInference would follow the trained model’s capability to generalize from the learned features of band triplets to unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
