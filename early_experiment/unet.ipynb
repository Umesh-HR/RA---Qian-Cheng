{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet \n",
    "\n",
    "- pre-trained with Car dataset: https://github.com/milesial/Pytorch-UNet/blob/master/README.md\n",
    "\n",
    "\n",
    "- pre-trained with brain dataset: https://github.com/mateuszbuda/brain-segmentation-pytorch/blob/master/README.md\n",
    "\n",
    "\n",
    "- Docker: a platform that allows you to develop, ship, and run applications in containers. Containers are lightweight, portable, and self-sufficient \n",
    "          environments that include everything needed to run an application—code, runtime, libraries, dependencies, and configurations.\n",
    "\n",
    "\n",
    "### Unet's encoder + decoder structure VS autoencoder:\n",
    "\n",
    "Is U-Net an Autoencoder?:\n",
    "✅ Yes, it follows an encoder-decoder structure like an autoencoder.\n",
    "❌ No, because it is designed for segmentation, not just reconstruction.\n",
    "\n",
    "- UNet use Skip connections, and Cross-entropy, Dice loss, IoU loss.\n",
    "\n",
    "Merging the segmenting results of each 3-band subset\n",
    "-\tMajority Voting: Assign each pixel the most frequently predicted class from different band combinations.\n",
    "-\tWeighted Averaging: Give more importance to specific bands or results with higher confidence scores.\n",
    "-\tFeature Fusion via CNN or MLP: Use a post-processing model to learn the optimal way to fuse predictions from different band combinations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available\n",
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "x = torch.randn((10, 10), device=device)\n",
    "y = torch.randn((10, 10), device=device)\n",
    "z = x + y  # this should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure using MPS (Metal) on Mac\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model with map_location: model.pth is the saved checkpoint\n",
    "# model = torch.load(\"model.pth\", map_location=device)\n",
    "# Move the model to the correct device\n",
    "# model.to(device)\n",
    "\n",
    "net = torch.hub.load('milesial/Pytorch-UNet', 'unet_carvana', pretrained=True, scale=0.5, map_location=device)\n",
    "# Move the model to the correct device\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Official UNet Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hsi/lib/python3.10/site-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/zipball/master\" to /Users/seaqueue/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/releases/download/v1.0/unet-e012d006.pt\" to /Users/seaqueue/.cache/torch/hub/checkpoints/unet-e012d006.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/TCGA_CS_4944.png\", \"TCGA_CS_4944.png\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hsi/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/hsi/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FF5E77A4-1F04-398B-B781-976783A281B8> /opt/anaconda3/envs/hsi/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/hsi/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/hsi/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/hsi/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/hsi/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "filename = '/Users/seaqueue/Documents/AI/Research/blueberry/understand_HSI/dct_compressed_034.png'\n",
    "input_image = Image.open(filename)\n",
    "m, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=m, std=s),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "print(torch.round(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved\n"
     ]
    }
   ],
   "source": [
    "# Convert to PIL image\n",
    "to_pil = transforms.ToPILImage()\n",
    "pil_image = to_pil(output[0])\n",
    "\n",
    "# Save the image\n",
    "pil_image.save(\"pca_unet_out.png\")\n",
    "\n",
    "print(\"Image saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
